{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n#%matplotlib inline\n\n\n\n# =============================================================================\n# Load Data\n# =============================================================================\n\n#!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv\ndf = pd.read_csv('loan_train.csv')\nprint(df.head())\nprint(df.shape)\n\ndf['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\nprint(df.head())\nprint(df.columns)\n#Index(['Unnamed: 0', 'Unnamed: 0.1', 'loan_status', 'Principal', 'terms',\n#       'effective_date', 'due_date', 'age', 'education', 'Gender'],\n#      dtype='object')\n\n\n\n\n# =============================================================================\n# Data visualization and pre-processing\n# =============================================================================\ndf['loan_status'].value_counts()\n\n\nimport seaborn as sns\n\n\n# \u6570\u636e\u5206\u5e03\uff1a\u6027\u522b\uff0c\u8d37\u6b3e\u91d1\u989d\uff0c\u8fd8\u6b3e\u72b6\u6001\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n\n#df.groupby('Gender').count()\n#df.groupby(['Gender', 'Principal', 'loan_status']).count()\n\n\n\n# \u6570\u636e\u5206\u5e03\uff1a\u6027\u522b\uff0c\u5e74\u9f84\uff0c\u8fd8\u6b3e\u72b6\u6001\nbins = np.linspace(df.age.min(), df.age.max(), 30)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n\n#df.groupby(['Gender', 'age', 'loan_status']).count()\n\n\n\n\n\n# =============================================================================\n# Pre-processing: Feature selection/extraction\n# =============================================================================\ndf['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 8)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n\n#df.groupby(['Gender', 'dayofweek', 'loan_status']).count()\n\n\n#weekend = Fri.Sat.Sun\ndf['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head()\n\n\n# \u903e\u671f\u8fd8\u6b3e\u4e0e\u6027\u522b\u6709\u5173\u5417\uff1f\ndf.groupby(['Gender'])['loan_status'].value_counts(normalize=True)\n#Gender  loan_status\n#female  PAIDOFF        0.865385\n#        COLLECTION     0.134615\n#male    PAIDOFF        0.731293\n#        COLLECTION     0.268707\n#Name: loan_status, dtype: float64\n#86 % of female pay there loans while only 73 % of males pay there loan\n\n\n# \u903e\u671f\u8fd8\u6b3e\u4e0e\u6559\u80b2\u7a0b\u5ea6\u6709\u5173\u5417\uff1f\ndf.groupby(['education'])['loan_status'].value_counts(normalize=True)\n#education             loan_status\n#Bechalor              PAIDOFF        0.750000\n#                      COLLECTION     0.250000\n#High School or Below  PAIDOFF        0.741722\n#                      COLLECTION     0.258278\n#Master or Above       COLLECTION     0.500000\n#                      PAIDOFF        0.500000\n#college               PAIDOFF        0.765101\n#                      COLLECTION     0.234899\n#Name: loan_status, dtype: float64\n# \u4f3c\u4e4e Master or Above \u7684\u4eba\u7fa4\u903e\u671f\u8fd8\u6b3e\u4e25\u91cd\n#(df['education']=='Master or Above').value_counts()\n#False    344\n#True       2\n# \u6837\u672c\u592a\u5c11\uff0c\u4e0d\u8bf4\u660e\u95ee\u9898\n\n\n\n# Gender --> [0,1]\n# loan_status --> [0,1]\ndf['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf['loan_status'].replace(to_replace=['PAIDOFF','COLLECTION'], value=[0,1],inplace=True)\ndf.head()\n\n\n\n\n\n# =============================================================================\n# Feature selection\n# =============================================================================\n#One Hot Encoding\ndf[['Principal','terms','age','Gender','education']].head()\n\nFeature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()\n\nX = Feature\nX[0:5]\n\ny = df['loan_status'].values\ny[0:5]\n\n\n# =============================================================================\n# Normalize Data\n# =============================================================================\nX= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]\n\n\n\n\n\n# =============================================================================\n# Classification\n# =============================================================================\n\n# =============================================================================\n# K Nearest Neighbor(KNN)\n# =============================================================================\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nknn_X_train, knn_X_test, knn_y_train, knn_y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', knn_X_train.shape,  knn_y_train.shape)\nprint ('Test set:', knn_X_test.shape,  knn_y_test.shape)\n\n\nKs = 100\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(knn_X_train, knn_y_train)\n    knn_yhat=neigh.predict(knn_X_test)\n    mean_acc[n-1] = metrics.accuracy_score(knn_y_test, knn_yhat)\n    std_acc[n-1]=np.std(knn_yhat==knn_y_test)/np.sqrt(knn_yhat.shape[0])\n\nprint(mean_acc)\n\n\n#Plot model accuracy for Different number of Neighbors\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()\n\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n\n\nk = mean_acc.argmax()+1\nloadKNN = KNeighborsClassifier(n_neighbors = k).fit(X, y)\n\n\n\n\n# =============================================================================\n# Decision Tree\n# =============================================================================\nfrom sklearn.tree import DecisionTreeClassifier\nloanTree = DecisionTreeClassifier(criterion=\"entropy\").fit(X, y)\n#loanTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4).fit(X, y)\n\n\n\n\n\n\n# =============================================================================\n# Support Vector Machine\n# =============================================================================\nfrom sklearn import svm\nloanSVM = svm.SVC(kernel='rbf').fit(X, y)\n#loanSVM = svm.SVC(kernel='linear').fit(X, y)\n\n\n\n\n\n\n\n# =============================================================================\n# Logistic Regression\n# =============================================================================\nfrom sklearn.linear_model import LogisticRegression\nloanLR = LogisticRegression(C=0.01, solver='sag').fit(X, y)\n#loanLR = LogisticRegression(C=0.01, solver='liblinear').fit(X, y)\n\n\n\n\n\n\n\n# =============================================================================\n# Model Evaluation using Test set\n# =============================================================================\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n\n\ntest_df = pd.read_csv('loan_test.csv')\ntest_df.head()\n\ntest_df['due_date'] = pd.to_datetime(df['due_date'])\ntest_df['effective_date'] = pd.to_datetime(df['effective_date'])\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ntest_df.head()\n\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ntest_df['loan_status'].replace(to_replace=['PAIDOFF','COLLECTION'], value=[0,1],inplace=True)\ntest_df.head()\n\nX_test = test_df[['Principal','terms','age','Gender','weekend']]\nX_test = pd.concat([X_test,pd.get_dummies(test_df['education'])], axis=1)\nX_test.drop(['Master or Above'], axis = 1,inplace=True)\nX_test= preprocessing.StandardScaler().fit(X_test).transform(X_test)\nX_test[0:5]\n\ny_test = test_df['loan_status'].values\ny_test[0:5]\n\n\n\n\n\n# =============================================================================\n# K Nearest Neighbor(KNN)\n# =============================================================================\n\nyhat = loadKNN.predict(X_test)\n\njaccardKNN = jaccard_similarity_score(y_test, yhat)\nf1scoreKNN = f1_score(y_test, yhat, average='weighted')\n\nprint(\"KNN\", jaccardKNN, f1scoreKNN)\n\n\n\n# =============================================================================\n# Decision Tree\n# =============================================================================\nyhat = loanTree.predict(X_test)\n\njaccardTree = jaccard_similarity_score(y_test, yhat)\nf1scoreTree = f1_score(y_test, yhat, average='weighted')\n\nprint(\"Tree\", jaccardTree, f1scoreTree)\n\n\n\n# =============================================================================\n# Support Vector Machine\n# =============================================================================\nyhat = loanSVM.predict(X_test)\n\njaccardSVM = jaccard_similarity_score(y_test, yhat)\nf1scoreSVM = f1_score(y_test, yhat, average='weighted')\n\nprint(\"SVM\", jaccardSVM, f1scoreSVM)\n\n\n\n\n# =============================================================================\n# Logistic Regression\n# =============================================================================\nyhat = loanLR.predict(X_test)\nyhat_prob = loanLR.predict_proba(X_test)\n\njaccardLR = jaccard_similarity_score(y_test, yhat)\nf1scoreLR = f1_score(y_test, yhat, average='weighted', labels=np.unique(yhat))\nloglossLR = log_loss(y_test, yhat_prob)\n\nprint(\"LR\", jaccardLR, f1scoreLR, loglossLR)\n\n\n\n\n# =============================================================================\n# Report\n# =============================================================================\nreport = {'Algorithm': ['KNN', 'Decision Tree', 'SVM', 'Logistic Regression'], \n          'Jaccard': [jaccardKNN, jaccardTree, jaccardSVM, jaccardLR],\n          'F1-score': [f1scoreKNN, f1scoreTree, f1scoreSVM, f1scoreLR],\n          'LogLoss': ['NA', 'NA', 'NA', loglossLR] }\ndf_report = pd.DataFrame(data=report)\ndf_report.set_index('Algorithm', inplace=True)\nprint(df_report)\n", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}